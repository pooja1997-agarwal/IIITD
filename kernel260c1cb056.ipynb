{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_label.pkl', 'train_image.pkl', 'test_image.pkl']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('../input/train_image.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_label.pkl', 'rb') as f:\n",
    "    label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/test_image.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #model will be trained on GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reshape(8000, 28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reshape(2000,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'A',\n",
    " 2: 'C',\n",
    " 3: 'D',\n",
    " 6: 'G',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc2df5d8b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train[10], (28,28))\n",
    "curr_lbl = label[10]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(test[10], (28,28))\n",
    "#curr_lbl = label[10]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "#plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 28, 28, 1), (2000, 28, 28, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train.reshape(-1, 28,28, 1)\n",
    "test_data = test.reshape(-1, 28,28, 1)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), dtype('int64'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtype, test_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 255)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / np.max(train_data)\n",
    "test_data = test_data / np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
    "                                                             train_data,\n",
    "                                                             test_size=0.2,\n",
    "                                                             random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 200\n",
    "inChannel = 1\n",
    "x, y = 28, 28\n",
    "input_img = Input(shape = (x, y, inChannel))\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4\n",
    "\n",
    "def decoder(conv4):    \n",
    "    #decoder\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4) #7 x 7 x 128\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoder(encoder(input_img)))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 7, 7, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 7, 7, 64)          73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 1,758,657\n",
      "Trainable params: 1,755,841\n",
      "Non-trainable params: 2,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 6s 933us/step - loss: 0.0442 - val_loss: 0.0780\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0222 - val_loss: 0.1277\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 2s 379us/step - loss: 0.0167 - val_loss: 0.0276\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0140 - val_loss: 0.0235\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0123 - val_loss: 0.0181\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 2s 378us/step - loss: 0.0103 - val_loss: 0.0152\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0091 - val_loss: 0.0139\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 2s 378us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0082 - val_loss: 0.0097\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 2s 378us/step - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0073 - val_loss: 0.0086\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 2s 378us/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 2s 379us/step - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0064 - val_loss: 0.0116\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0061 - val_loss: 0.0114\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 2s 383us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 2s 380us/step - loss: 0.0053 - val_loss: 0.0085\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 2s 379us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0050 - val_loss: 0.0072\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0044 - val_loss: 0.0071\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 2s 389us/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 2s 385us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 39/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 40/200\n",
      "6400/6400 [==============================] - 2s 380us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 2s 381us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 2s 378us/step - loss: 0.0036 - val_loss: 0.0088\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 2s 379us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 54/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 55/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 56/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0033 - val_loss: 0.0094\n",
      "Epoch 57/200\n",
      "6400/6400 [==============================] - 2s 379us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 58/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 59/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 60/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 61/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Epoch 62/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0033 - val_loss: 0.0059\n",
      "Epoch 63/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0032 - val_loss: 0.0065\n",
      "Epoch 64/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 65/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0031 - val_loss: 0.0127\n",
      "Epoch 66/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0031 - val_loss: 0.0058\n",
      "Epoch 67/200\n",
      "6400/6400 [==============================] - 2s 379us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 68/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 69/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 70/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 71/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 72/200\n",
      "6400/6400 [==============================] - 2s 379us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 73/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 74/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0029 - val_loss: 0.0150\n",
      "Epoch 75/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 76/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 77/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0028 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 79/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 80/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 81/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 82/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 83/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 84/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 85/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 86/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 87/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 88/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 89/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 90/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 91/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 92/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 93/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 94/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 95/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 96/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 97/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 98/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 99/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 100/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 101/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 102/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0023 - val_loss: 0.0049\n",
      "Epoch 103/200\n",
      "6400/6400 [==============================] - 2s 380us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 104/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 105/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 106/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 107/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 108/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 109/200\n",
      "6400/6400 [==============================] - 2s 378us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 110/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 111/200\n",
      "6400/6400 [==============================] - 2s 378us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 112/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 113/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 114/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 115/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 116/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 117/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 118/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 119/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 120/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 121/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 122/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 123/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 124/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 125/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 126/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 127/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 128/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 129/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 130/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 131/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 132/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 133/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 134/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 135/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 136/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 137/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 138/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 139/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 140/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 141/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 142/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 143/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 144/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 145/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 146/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 147/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 148/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 149/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 150/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 151/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 152/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 153/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 154/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0017 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 156/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 157/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 158/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 159/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 160/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 161/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 162/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 163/200\n",
      "6400/6400 [==============================] - 3s 392us/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 164/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 165/200\n",
      "6400/6400 [==============================] - 2s 382us/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 166/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 167/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 168/200\n",
      "6400/6400 [==============================] - 2s 370us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 169/200\n",
      "6400/6400 [==============================] - 2s 369us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 170/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 171/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 172/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 173/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 174/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 175/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 176/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 177/200\n",
      "6400/6400 [==============================] - 2s 369us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 178/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 179/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 180/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 181/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 182/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 183/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 184/200\n",
      "6400/6400 [==============================] - 2s 371us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 185/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 186/200\n",
      "6400/6400 [==============================] - 2s 376us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 187/200\n",
      "6400/6400 [==============================] - 2s 366us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 188/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 189/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0015 - val_loss: 0.0047\n",
      "Epoch 190/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 191/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 192/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 193/200\n",
      "6400/6400 [==============================] - 2s 380us/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 194/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 195/200\n",
      "6400/6400 [==============================] - 2s 377us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 196/200\n",
      "6400/6400 [==============================] - 2s 372us/step - loss: 0.0015 - val_loss: 0.0051\n",
      "Epoch 197/200\n",
      "6400/6400 [==============================] - 2s 375us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 198/200\n",
      "6400/6400 [==============================] - 2s 373us/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 199/200\n",
      "6400/6400 [==============================] - 2s 374us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 200/200\n",
      "6400/6400 [==============================] - 2s 370us/step - loss: 0.0015 - val_loss: 0.0041\n"
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(200)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 0\n",
      "After conversion to one-hot: [1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = keras.utils.np_utils.to_categorical(label)\n",
    "\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', label[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,valid_X,train_label,valid_label = train_test_split(train_data,train_Y_one_hot,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6400, 28, 28, 1), (1600, 28, 28, 1), (6400, 7), (1600, 7))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(enco):\n",
    "    flat = Flatten()(enco)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(den)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = encoder(input_img)\n",
    "full_model = Model(input_img,fc(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model.layers[:19],autoencoder.layers[0:19]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-8.92826021e-02,  1.20219760e-01,  9.46458802e-03,\n",
       "          6.52166232e-02,  1.85997859e-01, -6.71763197e-02,\n",
       "         -8.58565941e-02, -1.99856564e-01, -6.24276586e-02,\n",
       "          1.33293331e-01, -1.68890998e-01,  1.18645422e-01,\n",
       "          1.93988860e-01,  2.62400568e-01,  7.07430691e-02,\n",
       "          2.45019019e-01,  1.44162819e-01, -5.77673972e-01,\n",
       "         -2.58288622e-01, -7.07396120e-02,  6.44430071e-02,\n",
       "         -1.95830643e-01,  2.10087031e-01, -2.24126223e-02,\n",
       "          3.00603449e-01,  4.92660552e-02,  6.61354959e-02,\n",
       "          8.80498514e-02, -5.19504473e-02, -1.57302082e-01,\n",
       "         -3.81634772e-01, -4.73297609e-04]],\n",
       "\n",
       "       [[-9.59830638e-03, -1.10451095e-01,  1.40998423e-01,\n",
       "          2.49244288e-01,  5.32437414e-02,  1.43699288e-01,\n",
       "          1.87271938e-01, -8.99593085e-02,  1.16814569e-01,\n",
       "         -3.01000714e-01, -1.00562781e-01, -2.40664959e-01,\n",
       "          1.41868010e-01, -1.89484492e-01,  2.88667381e-01,\n",
       "          7.42339417e-02,  2.18929410e-01, -2.63741136e-01,\n",
       "         -3.37666608e-02, -2.86089897e-01, -2.31356636e-01,\n",
       "         -1.62074655e-01, -5.60069866e-02, -1.62439197e-01,\n",
       "         -2.49988101e-02,  1.76084012e-01,  1.12446793e-03,\n",
       "          6.63214773e-02, -1.22450247e-01,  4.25744839e-02,\n",
       "         -3.54965739e-02, -1.45345405e-01]],\n",
       "\n",
       "       [[-1.94931775e-01,  2.63812989e-02,  2.13285064e-04,\n",
       "          1.64857343e-01, -2.87074238e-01,  2.40223035e-01,\n",
       "         -1.43944755e-01,  2.12381944e-01,  2.05338597e-01,\n",
       "         -2.02395260e-01,  1.80709809e-02,  6.20473996e-02,\n",
       "          1.42331317e-01, -2.27021322e-01,  1.84503216e-02,\n",
       "         -1.36426196e-01, -1.23142786e-01, -2.00093240e-01,\n",
       "         -2.55433589e-01,  7.14894980e-02, -5.30722439e-02,\n",
       "          1.00618184e-01,  6.42116293e-02, -2.32891187e-01,\n",
       "          1.93458140e-01,  7.04193115e-02, -2.10046574e-01,\n",
       "          8.92635360e-02,  2.25921988e-01, -1.08700357e-01,\n",
       "         -2.24417299e-01,  2.48685285e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-8.92826021e-02,  1.20219760e-01,  9.46458802e-03,\n",
       "          6.52166232e-02,  1.85997859e-01, -6.71763197e-02,\n",
       "         -8.58565941e-02, -1.99856564e-01, -6.24276586e-02,\n",
       "          1.33293331e-01, -1.68890998e-01,  1.18645422e-01,\n",
       "          1.93988860e-01,  2.62400568e-01,  7.07430691e-02,\n",
       "          2.45019019e-01,  1.44162819e-01, -5.77673972e-01,\n",
       "         -2.58288622e-01, -7.07396120e-02,  6.44430071e-02,\n",
       "         -1.95830643e-01,  2.10087031e-01, -2.24126223e-02,\n",
       "          3.00603449e-01,  4.92660552e-02,  6.61354959e-02,\n",
       "          8.80498514e-02, -5.19504473e-02, -1.57302082e-01,\n",
       "         -3.81634772e-01, -4.73297609e-04]],\n",
       "\n",
       "       [[-9.59830638e-03, -1.10451095e-01,  1.40998423e-01,\n",
       "          2.49244288e-01,  5.32437414e-02,  1.43699288e-01,\n",
       "          1.87271938e-01, -8.99593085e-02,  1.16814569e-01,\n",
       "         -3.01000714e-01, -1.00562781e-01, -2.40664959e-01,\n",
       "          1.41868010e-01, -1.89484492e-01,  2.88667381e-01,\n",
       "          7.42339417e-02,  2.18929410e-01, -2.63741136e-01,\n",
       "         -3.37666608e-02, -2.86089897e-01, -2.31356636e-01,\n",
       "         -1.62074655e-01, -5.60069866e-02, -1.62439197e-01,\n",
       "         -2.49988101e-02,  1.76084012e-01,  1.12446793e-03,\n",
       "          6.63214773e-02, -1.22450247e-01,  4.25744839e-02,\n",
       "         -3.54965739e-02, -1.45345405e-01]],\n",
       "\n",
       "       [[-1.94931775e-01,  2.63812989e-02,  2.13285064e-04,\n",
       "          1.64857343e-01, -2.87074238e-01,  2.40223035e-01,\n",
       "         -1.43944755e-01,  2.12381944e-01,  2.05338597e-01,\n",
       "         -2.02395260e-01,  1.80709809e-02,  6.20473996e-02,\n",
       "          1.42331317e-01, -2.27021322e-01,  1.84503216e-02,\n",
       "         -1.36426196e-01, -1.23142786e-01, -2.00093240e-01,\n",
       "         -2.55433589e-01,  7.14894980e-02, -5.30722439e-02,\n",
       "          1.00618184e-01,  6.42116293e-02, -2.32891187e-01,\n",
       "          1.93458140e-01,  7.04193115e-02, -2.10046574e-01,\n",
       "          8.92635360e-02,  2.25921988e-01, -1.08700357e-01,\n",
       "         -2.24417299e-01,  2.48685285e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,782,183\n",
      "Trainable params: 1,606,663\n",
      "Non-trainable params: 1,175,520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 3s 493us/step - loss: 0.5764 - acc: 0.8113 - val_loss: 0.3891 - val_acc: 0.8531\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 0.2175 - acc: 0.9191 - val_loss: 0.4111 - val_acc: 0.8425\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.1088 - acc: 0.9608 - val_loss: 0.4182 - val_acc: 0.8500\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 0.0590 - acc: 0.9816 - val_loss: 0.5113 - val_acc: 0.8544\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 1s 123us/step - loss: 0.0316 - acc: 0.9909 - val_loss: 0.5072 - val_acc: 0.8562\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 1s 130us/step - loss: 0.0108 - acc: 0.9986 - val_loss: 0.5198 - val_acc: 0.8681\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 1s 127us/step - loss: 0.0049 - acc: 0.9997 - val_loss: 0.5282 - val_acc: 0.8694\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5365 - val_acc: 0.8694\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5440 - val_acc: 0.8725\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 8.7742e-04 - acc: 1.0000 - val_loss: 0.5497 - val_acc: 0.8700\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 7.1082e-04 - acc: 1.0000 - val_loss: 0.5576 - val_acc: 0.8694\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 5.9518e-04 - acc: 1.0000 - val_loss: 0.5619 - val_acc: 0.8731\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 5.2084e-04 - acc: 1.0000 - val_loss: 0.5709 - val_acc: 0.8738\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 4.3033e-04 - acc: 1.0000 - val_loss: 0.5732 - val_acc: 0.8725\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 3.8744e-04 - acc: 1.0000 - val_loss: 0.5792 - val_acc: 0.8731\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 3.3367e-04 - acc: 1.0000 - val_loss: 0.5857 - val_acc: 0.8731\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 2.8763e-04 - acc: 1.0000 - val_loss: 0.5907 - val_acc: 0.8706\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 2.5725e-04 - acc: 1.0000 - val_loss: 0.5935 - val_acc: 0.8738\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 2.4609e-04 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.8731\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 2.1122e-04 - acc: 1.0000 - val_loss: 0.6029 - val_acc: 0.8725\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.8763e-04 - acc: 1.0000 - val_loss: 0.6068 - val_acc: 0.8738\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 1s 127us/step - loss: 1.8377e-04 - acc: 1.0000 - val_loss: 0.6083 - val_acc: 0.8712\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.6117e-04 - acc: 1.0000 - val_loss: 0.6134 - val_acc: 0.8725\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 1s 127us/step - loss: 1.4437e-04 - acc: 1.0000 - val_loss: 0.6188 - val_acc: 0.8731\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.2874e-04 - acc: 1.0000 - val_loss: 0.6219 - val_acc: 0.8719\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 1.2051e-04 - acc: 1.0000 - val_loss: 0.6241 - val_acc: 0.8731\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 1.1220e-04 - acc: 1.0000 - val_loss: 0.6281 - val_acc: 0.8712\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.7364 - val_acc: 0.8600\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 0.7239 - acc: 0.8786 - val_loss: 0.9916 - val_acc: 0.8037\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 0.2663 - acc: 0.9261 - val_loss: 0.6735 - val_acc: 0.8462\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0759 - acc: 0.9769 - val_loss: 0.6646 - val_acc: 0.8419\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0208 - acc: 0.9953 - val_loss: 0.6788 - val_acc: 0.8612\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 0.0077 - acc: 0.9991 - val_loss: 0.6675 - val_acc: 0.8550\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.6872 - val_acc: 0.8550\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 1s 128us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.7000 - val_acc: 0.8569\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.7130 - val_acc: 0.8606\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 0.8581\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 8.5526e-04 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.8619\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 7.1536e-04 - acc: 1.0000 - val_loss: 0.7411 - val_acc: 0.8600\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 5.8264e-04 - acc: 1.0000 - val_loss: 0.7481 - val_acc: 0.8631\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 5.3724e-04 - acc: 1.0000 - val_loss: 0.7534 - val_acc: 0.8619\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 4.3817e-04 - acc: 1.0000 - val_loss: 0.7608 - val_acc: 0.8619\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 3.9135e-04 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.8619\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 3.5544e-04 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.8638\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 3.2660e-04 - acc: 1.0000 - val_loss: 0.7772 - val_acc: 0.8625\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 3.0088e-04 - acc: 1.0000 - val_loss: 0.7802 - val_acc: 0.8656\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 2.4523e-04 - acc: 1.0000 - val_loss: 0.7866 - val_acc: 0.8644\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 2.2806e-04 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.8650\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 2.1151e-04 - acc: 1.0000 - val_loss: 0.7978 - val_acc: 0.8662\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 1.9925e-04 - acc: 1.0000 - val_loss: 0.8026 - val_acc: 0.8638\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.8078e-04 - acc: 1.0000 - val_loss: 0.8071 - val_acc: 0.8650\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 1s 127us/step - loss: 1.7170e-04 - acc: 1.0000 - val_loss: 0.8097 - val_acc: 0.8644\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 2.3906e-04 - acc: 1.0000 - val_loss: 0.8625 - val_acc: 0.8581\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.9456 - val_acc: 0.8538\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0726 - acc: 0.9805 - val_loss: 1.0967 - val_acc: 0.8369\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.1418 - acc: 0.9636 - val_loss: 0.9311 - val_acc: 0.8431\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 1s 127us/step - loss: 0.0569 - acc: 0.9830 - val_loss: 0.9873 - val_acc: 0.8450\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 1s 136us/step - loss: 0.0299 - acc: 0.9922 - val_loss: 1.0114 - val_acc: 0.8450\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 0.0126 - acc: 0.9963 - val_loss: 1.0003 - val_acc: 0.8606\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.9938 - val_acc: 0.8500\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 1s 129us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 1.0302 - val_acc: 0.8506\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 1s 128us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.9969 - val_acc: 0.8506\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 2.3363e-04 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.8531\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 1s 127us/step - loss: 1.7881e-04 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.8531\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.2453e-04 - acc: 1.0000 - val_loss: 0.9965 - val_acc: 0.8538\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.1297e-04 - acc: 1.0000 - val_loss: 0.9979 - val_acc: 0.8538\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.0803e-04 - acc: 1.0000 - val_loss: 0.9991 - val_acc: 0.8556\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 9.7308e-05 - acc: 1.0000 - val_loss: 1.0013 - val_acc: 0.8562\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 9.6024e-05 - acc: 1.0000 - val_loss: 1.0043 - val_acc: 0.8556\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 8.1945e-05 - acc: 1.0000 - val_loss: 1.0075 - val_acc: 0.8556\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 7.5859e-05 - acc: 1.0000 - val_loss: 1.0089 - val_acc: 0.8556\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 1s 131us/step - loss: 6.6327e-05 - acc: 1.0000 - val_loss: 1.0106 - val_acc: 0.8556\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 6.1100e-05 - acc: 1.0000 - val_loss: 1.0134 - val_acc: 0.8550\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 5.8169e-05 - acc: 1.0000 - val_loss: 1.0150 - val_acc: 0.8550\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 5.4802e-05 - acc: 1.0000 - val_loss: 1.0174 - val_acc: 0.8556\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 5.4188e-05 - acc: 1.0000 - val_loss: 1.0198 - val_acc: 0.8562\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 4.7494e-05 - acc: 1.0000 - val_loss: 1.0214 - val_acc: 0.8556\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 4.7683e-05 - acc: 1.0000 - val_loss: 1.0239 - val_acc: 0.8569\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 4.4471e-05 - acc: 1.0000 - val_loss: 1.0269 - val_acc: 0.8575\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 1s 130us/step - loss: 3.9497e-05 - acc: 1.0000 - val_loss: 1.0283 - val_acc: 0.8575\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 4.1538e-05 - acc: 1.0000 - val_loss: 1.0296 - val_acc: 0.8575\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 3.6526e-05 - acc: 1.0000 - val_loss: 1.0328 - val_acc: 0.8575\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 3.3640e-05 - acc: 1.0000 - val_loss: 1.0348 - val_acc: 0.8588\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 3.2524e-05 - acc: 1.0000 - val_loss: 1.0362 - val_acc: 0.8588\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 1s 128us/step - loss: 3.1821e-05 - acc: 1.0000 - val_loss: 1.0369 - val_acc: 0.8575\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 1s 127us/step - loss: 2.6860e-05 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.8575\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 2.7434e-05 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.8581\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 2.4900e-05 - acc: 1.0000 - val_loss: 1.0430 - val_acc: 0.8581\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 2.4867e-05 - acc: 1.0000 - val_loss: 1.0451 - val_acc: 0.8588\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 2.3548e-05 - acc: 1.0000 - val_loss: 1.0470 - val_acc: 0.8581\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 2.2466e-05 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.8581\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 2.2155e-05 - acc: 1.0000 - val_loss: 1.0500 - val_acc: 0.8575\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 1.9536e-05 - acc: 1.0000 - val_loss: 1.0526 - val_acc: 0.8575\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.8294e-05 - acc: 1.0000 - val_loss: 1.0551 - val_acc: 0.8581\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.7061e-05 - acc: 1.0000 - val_loss: 1.0563 - val_acc: 0.8581\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.7239e-05 - acc: 1.0000 - val_loss: 1.0576 - val_acc: 0.8581\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 1.4880e-05 - acc: 1.0000 - val_loss: 1.0597 - val_acc: 0.8581\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 1s 124us/step - loss: 1.5403e-05 - acc: 1.0000 - val_loss: 1.0616 - val_acc: 0.8581\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 1s 125us/step - loss: 1.5834e-05 - acc: 1.0000 - val_loss: 1.0641 - val_acc: 0.8588\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 1s 126us/step - loss: 1.5872e-05 - acc: 1.0000 - val_loss: 1.0651 - val_acc: 0.8588\n"
     ]
    }
   ],
   "source": [
    "classify_train = full_model.fit(train_X, train_label, batch_size=64,epochs=100,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save_weights('autoencoder_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:19]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 6s 886us/step - loss: 0.0756 - acc: 0.9842 - val_loss: 1.1657 - val_acc: 0.8269\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 0.0701 - acc: 0.9813 - val_loss: 1.1240 - val_acc: 0.8475\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 0.0699 - acc: 0.9814 - val_loss: 1.1396 - val_acc: 0.8281\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 0.0575 - acc: 0.9838 - val_loss: 1.0339 - val_acc: 0.8462\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 0.0360 - acc: 0.9878 - val_loss: 1.0356 - val_acc: 0.8506\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 0.0224 - acc: 0.9930 - val_loss: 0.9913 - val_acc: 0.8525\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 0.0089 - acc: 0.9969 - val_loss: 1.0262 - val_acc: 0.8475\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 0.0019 - acc: 0.9991 - val_loss: 1.0149 - val_acc: 0.8569\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 4.8661e-04 - acc: 1.0000 - val_loss: 1.0234 - val_acc: 0.8688\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 1.0157e-04 - acc: 1.0000 - val_loss: 1.0195 - val_acc: 0.8688\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 7.8755e-05 - acc: 1.0000 - val_loss: 1.0219 - val_acc: 0.8688\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 5.6432e-05 - acc: 1.0000 - val_loss: 1.0261 - val_acc: 0.8688\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 4.9256e-05 - acc: 1.0000 - val_loss: 1.0289 - val_acc: 0.8681\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 4.5011e-05 - acc: 1.0000 - val_loss: 1.0319 - val_acc: 0.8681\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 4.1361e-05 - acc: 1.0000 - val_loss: 1.0323 - val_acc: 0.8688\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 3.6401e-05 - acc: 1.0000 - val_loss: 1.0358 - val_acc: 0.8688\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 3.4299e-05 - acc: 1.0000 - val_loss: 1.0382 - val_acc: 0.8681\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 2s 282us/step - loss: 2.9208e-05 - acc: 1.0000 - val_loss: 1.0407 - val_acc: 0.8675\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 2.7185e-05 - acc: 1.0000 - val_loss: 1.0428 - val_acc: 0.8675\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 2.4065e-05 - acc: 1.0000 - val_loss: 1.0461 - val_acc: 0.8669\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 2.2095e-05 - acc: 1.0000 - val_loss: 1.0487 - val_acc: 0.8675\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 2.1560e-05 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.8688\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 2s 290us/step - loss: 1.8165e-05 - acc: 1.0000 - val_loss: 1.0527 - val_acc: 0.8688\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 1.7556e-05 - acc: 1.0000 - val_loss: 1.0545 - val_acc: 0.8688\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 1.6092e-05 - acc: 1.0000 - val_loss: 1.0570 - val_acc: 0.8688\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 1.5091e-05 - acc: 1.0000 - val_loss: 1.0588 - val_acc: 0.8688\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 1.5800e-05 - acc: 1.0000 - val_loss: 1.0608 - val_acc: 0.8688\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 1.2456e-05 - acc: 1.0000 - val_loss: 1.0625 - val_acc: 0.8688\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 1.2808e-05 - acc: 1.0000 - val_loss: 1.0647 - val_acc: 0.8694\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 1.2639e-05 - acc: 1.0000 - val_loss: 1.0673 - val_acc: 0.8694\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 1.0985e-05 - acc: 1.0000 - val_loss: 1.0686 - val_acc: 0.8694\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 9.9049e-06 - acc: 1.0000 - val_loss: 1.0694 - val_acc: 0.8700\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 9.5188e-06 - acc: 1.0000 - val_loss: 1.0714 - val_acc: 0.8700\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 9.0834e-06 - acc: 1.0000 - val_loss: 1.0732 - val_acc: 0.8694\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 8.3988e-06 - acc: 1.0000 - val_loss: 1.0747 - val_acc: 0.8700\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 2s 289us/step - loss: 7.5374e-06 - acc: 1.0000 - val_loss: 1.0760 - val_acc: 0.8700\n",
      "Epoch 37/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 7.9599e-06 - acc: 1.0000 - val_loss: 1.0781 - val_acc: 0.8700\n",
      "Epoch 38/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 7.5861e-06 - acc: 1.0000 - val_loss: 1.0782 - val_acc: 0.8694\n",
      "Epoch 39/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 6.7061e-06 - acc: 1.0000 - val_loss: 1.0802 - val_acc: 0.8694\n",
      "Epoch 40/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 6.7865e-06 - acc: 1.0000 - val_loss: 1.0817 - val_acc: 0.8688\n",
      "Epoch 41/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 5.8019e-06 - acc: 1.0000 - val_loss: 1.0838 - val_acc: 0.8688\n",
      "Epoch 42/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 5.5750e-06 - acc: 1.0000 - val_loss: 1.0853 - val_acc: 0.8688\n",
      "Epoch 43/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 5.3771e-06 - acc: 1.0000 - val_loss: 1.0867 - val_acc: 0.8688\n",
      "Epoch 44/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 5.2339e-06 - acc: 1.0000 - val_loss: 1.0889 - val_acc: 0.8694\n",
      "Epoch 45/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 4.9453e-06 - acc: 1.0000 - val_loss: 1.0900 - val_acc: 0.8694\n",
      "Epoch 46/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 4.7477e-06 - acc: 1.0000 - val_loss: 1.0905 - val_acc: 0.8694\n",
      "Epoch 47/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 4.5202e-06 - acc: 1.0000 - val_loss: 1.0919 - val_acc: 0.8700\n",
      "Epoch 48/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 4.1267e-06 - acc: 1.0000 - val_loss: 1.0932 - val_acc: 0.8694\n",
      "Epoch 49/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 3.8579e-06 - acc: 1.0000 - val_loss: 1.0953 - val_acc: 0.8694\n",
      "Epoch 50/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 3.7066e-06 - acc: 1.0000 - val_loss: 1.0973 - val_acc: 0.8700\n",
      "Epoch 51/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 3.5474e-06 - acc: 1.0000 - val_loss: 1.0990 - val_acc: 0.8706\n",
      "Epoch 52/100\n",
      "6400/6400 [==============================] - 2s 289us/step - loss: 3.2781e-06 - acc: 1.0000 - val_loss: 1.1011 - val_acc: 0.8706\n",
      "Epoch 53/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 3.1129e-06 - acc: 1.0000 - val_loss: 1.1031 - val_acc: 0.8706\n",
      "Epoch 54/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 2.7700e-06 - acc: 1.0000 - val_loss: 1.1045 - val_acc: 0.8700\n",
      "Epoch 55/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 2.8184e-06 - acc: 1.0000 - val_loss: 1.1060 - val_acc: 0.8700\n",
      "Epoch 56/100\n",
      "6400/6400 [==============================] - 2s 290us/step - loss: 2.7394e-06 - acc: 1.0000 - val_loss: 1.1074 - val_acc: 0.8712\n",
      "Epoch 57/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 2.5827e-06 - acc: 1.0000 - val_loss: 1.1087 - val_acc: 0.8712\n",
      "Epoch 58/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 2.3210e-06 - acc: 1.0000 - val_loss: 1.1105 - val_acc: 0.8712\n",
      "Epoch 59/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 2.2604e-06 - acc: 1.0000 - val_loss: 1.1118 - val_acc: 0.8712\n",
      "Epoch 60/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 2.0698e-06 - acc: 1.0000 - val_loss: 1.1132 - val_acc: 0.8712\n",
      "Epoch 61/100\n",
      "6400/6400 [==============================] - 2s 281us/step - loss: 2.2597e-06 - acc: 1.0000 - val_loss: 1.1151 - val_acc: 0.8712\n",
      "Epoch 62/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 1.9910e-06 - acc: 1.0000 - val_loss: 1.1168 - val_acc: 0.8712\n",
      "Epoch 63/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 1.8665e-06 - acc: 1.0000 - val_loss: 1.1187 - val_acc: 0.8712\n",
      "Epoch 64/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 1.8351e-06 - acc: 1.0000 - val_loss: 1.1204 - val_acc: 0.8712\n",
      "Epoch 65/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 1.6833e-06 - acc: 1.0000 - val_loss: 1.1216 - val_acc: 0.8712\n",
      "Epoch 66/100\n",
      "6400/6400 [==============================] - 2s 282us/step - loss: 1.6634e-06 - acc: 1.0000 - val_loss: 1.1227 - val_acc: 0.8712\n",
      "Epoch 67/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 1.6589e-06 - acc: 1.0000 - val_loss: 1.1232 - val_acc: 0.8719\n",
      "Epoch 68/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 1.4441e-06 - acc: 1.0000 - val_loss: 1.1250 - val_acc: 0.8719\n",
      "Epoch 69/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 1.4398e-06 - acc: 1.0000 - val_loss: 1.1269 - val_acc: 0.8712\n",
      "Epoch 70/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 1.3006e-06 - acc: 1.0000 - val_loss: 1.1281 - val_acc: 0.8712\n",
      "Epoch 71/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 1.2546e-06 - acc: 1.0000 - val_loss: 1.1298 - val_acc: 0.8712\n",
      "Epoch 72/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 1.2299e-06 - acc: 1.0000 - val_loss: 1.1308 - val_acc: 0.8706\n",
      "Epoch 73/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 1.2390e-06 - acc: 1.0000 - val_loss: 1.1316 - val_acc: 0.8706\n",
      "Epoch 74/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 1.1266e-06 - acc: 1.0000 - val_loss: 1.1328 - val_acc: 0.8706\n",
      "Epoch 75/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 1.1014e-06 - acc: 1.0000 - val_loss: 1.1351 - val_acc: 0.8706\n",
      "Epoch 76/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 1.0033e-06 - acc: 1.0000 - val_loss: 1.1367 - val_acc: 0.8700\n",
      "Epoch 77/100\n",
      "6400/6400 [==============================] - 2s 282us/step - loss: 9.5268e-07 - acc: 1.0000 - val_loss: 1.1380 - val_acc: 0.8700\n",
      "Epoch 78/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 9.0874e-07 - acc: 1.0000 - val_loss: 1.1394 - val_acc: 0.8700\n",
      "Epoch 79/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 8.8209e-07 - acc: 1.0000 - val_loss: 1.1420 - val_acc: 0.8700\n",
      "Epoch 80/100\n",
      "6400/6400 [==============================] - 2s 301us/step - loss: 8.4639e-07 - acc: 1.0000 - val_loss: 1.1432 - val_acc: 0.8706\n",
      "Epoch 81/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 8.3295e-07 - acc: 1.0000 - val_loss: 1.1431 - val_acc: 0.8700\n",
      "Epoch 82/100\n",
      "6400/6400 [==============================] - 2s 292us/step - loss: 7.6046e-07 - acc: 1.0000 - val_loss: 1.1450 - val_acc: 0.8700\n",
      "Epoch 83/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 7.3339e-07 - acc: 1.0000 - val_loss: 1.1467 - val_acc: 0.8700\n",
      "Epoch 84/100\n",
      "6400/6400 [==============================] - 2s 282us/step - loss: 7.3314e-07 - acc: 1.0000 - val_loss: 1.1484 - val_acc: 0.8706\n",
      "Epoch 85/100\n",
      "6400/6400 [==============================] - 2s 294us/step - loss: 7.0631e-07 - acc: 1.0000 - val_loss: 1.1504 - val_acc: 0.8706\n",
      "Epoch 86/100\n",
      "6400/6400 [==============================] - 2s 284us/step - loss: 6.0903e-07 - acc: 1.0000 - val_loss: 1.1512 - val_acc: 0.8706\n",
      "Epoch 87/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 6.2029e-07 - acc: 1.0000 - val_loss: 1.1528 - val_acc: 0.8706\n",
      "Epoch 88/100\n",
      "6400/6400 [==============================] - 2s 289us/step - loss: 6.0829e-07 - acc: 1.0000 - val_loss: 1.1541 - val_acc: 0.8706\n",
      "Epoch 89/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 5.9671e-07 - acc: 1.0000 - val_loss: 1.1553 - val_acc: 0.8700\n",
      "Epoch 90/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 5.0489e-07 - acc: 1.0000 - val_loss: 1.1570 - val_acc: 0.8700\n",
      "Epoch 91/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 5.0459e-07 - acc: 1.0000 - val_loss: 1.1585 - val_acc: 0.8700\n",
      "Epoch 92/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 5.4169e-07 - acc: 1.0000 - val_loss: 1.1606 - val_acc: 0.8700\n",
      "Epoch 93/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 5.0434e-07 - acc: 1.0000 - val_loss: 1.1614 - val_acc: 0.8694\n",
      "Epoch 94/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 4.4151e-07 - acc: 1.0000 - val_loss: 1.1632 - val_acc: 0.8694\n",
      "Epoch 95/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 4.5430e-07 - acc: 1.0000 - val_loss: 1.1644 - val_acc: 0.8694\n",
      "Epoch 96/100\n",
      "6400/6400 [==============================] - 2s 286us/step - loss: 4.1629e-07 - acc: 1.0000 - val_loss: 1.1656 - val_acc: 0.8688\n",
      "Epoch 97/100\n",
      "6400/6400 [==============================] - 2s 283us/step - loss: 4.0381e-07 - acc: 1.0000 - val_loss: 1.1671 - val_acc: 0.8694\n",
      "Epoch 98/100\n",
      "6400/6400 [==============================] - 2s 288us/step - loss: 4.0283e-07 - acc: 1.0000 - val_loss: 1.1685 - val_acc: 0.8700\n",
      "Epoch 99/100\n",
      "6400/6400 [==============================] - 2s 285us/step - loss: 3.6305e-07 - acc: 1.0000 - val_loss: 1.1698 - val_acc: 0.8700\n",
      "Epoch 100/100\n",
      "6400/6400 [==============================] - 2s 287us/step - loss: 3.6086e-07 - acc: 1.0000 - val_loss: 1.1712 - val_acc: 0.8700\n"
     ]
    }
   ],
   "source": [
    "classify_train = full_model.fit(train_X, train_label, batch_size=64,epochs=100,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save_weights('classification_complete.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = classify_train.history['acc']\n",
    "val_accuracy = classify_train.history['val_acc']\n",
    "loss = classify_train.history['loss']\n",
    "val_loss = classify_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two plots, you can see that the model is overfitting since there is a big gap between the training and validation loss. In order to address overfitting, you will have to maybe use some regularization techniques like Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = full_model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600,), (1600, 7))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.96      0.97      0.97      2000\n",
      "     Class 1       0.98      0.98      0.98      2000\n",
      "     Class 2       0.98      0.99      0.99      2000\n",
      "     Class 3       0.97      0.95      0.96      2000\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8000\n",
      "   macro avg       0.97      0.97      0.97      8000\n",
      "weighted avg       0.97      0.97      0.97      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(4)]\n",
    "print(classification_report(label, predicted_classes,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = full_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(np.round(predictions),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'image_index':range(0,2000),'class':predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_index</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_index  class\n",
       "0            0      0\n",
       "1            1      0\n",
       "2            2      0\n",
       "3            3      0\n",
       "4            4      0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-50395e9f8ff7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pooja_Agarwal.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('Pooja_Agarwal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
